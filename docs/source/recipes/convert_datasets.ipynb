{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iux4BMHWHqUd"
      },
      "source": [
        "# Convert Dataset Formats\n",
        "\n",
        "This recipe demonstrates how to use FiftyOne to convert datasets on disk between common formats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kkt64BHqUf"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNPM5zuWHqUg"
      },
      "source": [
        "If you haven't already, install FiftyOne:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsrCDBh0HqUg"
      },
      "outputs": [],
      "source": [
        "pip install fiftyone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjMXPUnZHqUg"
      },
      "source": [
        "This notebook contains bash commands. To run it as a notebook, you must install the [Jupyter bash kernel](https://github.com/takluyver/bash_kernel) via the command below.\n",
        "\n",
        "Alternatively, you can just copy + paste the code blocks into your shell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiVG2gMEHqUg"
      },
      "outputs": [],
      "source": [
        "!pip install bash_kernel\n",
        "!python -m bash_kernel.install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMooNwQrHqUh"
      },
      "source": [
        "In this recipe we'll use the [FiftyOne Dataset Zoo](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/zoo_datasets.html) to download some open source datasets to work with.\n",
        "\n",
        "Specifically, we'll need [TensorFlow](https://www.tensorflow.org/) and [TensorFlow Datasets](https://www.tensorflow.org/datasets) installed to [access the datasets](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/zoo_datasets.html#customizing-your-ml-backend):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kTicbKNyHqUh",
        "outputId": "123b0c69-e401-478e-8233-da944e370f3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (4.9.9)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.7.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.9)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (18.1.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.17.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.22.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-datasets) (25.3.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.70.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m13VwRYdHqUh"
      },
      "source": [
        "## Download datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9nwfpRPHqUh"
      },
      "source": [
        "Download the test split of the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) from the [FiftyOne Dataset Zoo](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/zoo_datasets.html) using the command below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXPVtk_5HqUh"
      },
      "outputs": [],
      "source": [
        "# Download the test split of CIFAR-10\n",
        "fiftyone zoo datasets download cifar10 --split test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ShyLLXQHqUi"
      },
      "source": [
        "Download the validation split of the [KITTI dataset]( http://www.cvlibs.net/datasets/kitti) from the [FiftyOne Dataset Zoo](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/zoo_datasets.html) using the command below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnTuwEHUHqUi",
        "outputId": "30fe4a9e-193d-424e-d2f1-feeb6f860552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 'validation' already downloaded\n"
          ]
        }
      ],
      "source": [
        "# Download the validation split of KITTI\n",
        "fiftyone zoo datasets download kitti --split validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDznI2GHHqUi"
      },
      "source": [
        "## The fiftyone convert command"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J87z9YnMHqUi"
      },
      "source": [
        "The [FiftyOne CLI](https://voxel51.com/docs/fiftyone/cli/index.html) provides a number of utilities for importing and exporting datasets in a variety of common (or custom) formats.\n",
        "\n",
        "Specifically, the `fiftyone convert` command provides a convenient way to convert datasets on disk between formats by specifying the [fiftyone.types.Dataset](https://voxel51.com/docs/fiftyone/api/fiftyone.types.html#fiftyone.types.dataset_types.Dataset) type of the input and desired output.\n",
        "\n",
        "FiftyOne provides a collection of [builtin types](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#supported-formats) that you can use to read/write datasets in common formats out-of-the-box:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_hQe7Z6HqUi"
      },
      "source": [
        "<div class=\"convert-recipes-table\">\n",
        "\n",
        "| Dataset format                                                                                                                                       | Import Supported? | Export Supported? | Conversion Supported? |\n",
        "| ---------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------- | ----------------- | --------------------- |\n",
        "| [ImageDirectory](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#imagedirectory)                                         | ✓                 | ✓                 | ✓                     |\n",
        "| [VideoDirectory](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#videodirectory)                                         | ✓                 | ✓                 | ✓                     |\n",
        "| [FiftyOneImageClassificationDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#fiftyoneimageclassificationdataset) | ✓                 | ✓                 | ✓                     |\n",
        "| [ImageClassificationDirectoryTree](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#imageclassificationdirectorytree)     | ✓                 | ✓                 | ✓                     |\n",
        "| [TFImageClassificationDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#tfimageclassificationdataset)             | ✓                 | ✓                 | ✓                     |\n",
        "| [FiftyOneImageDetectionDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#fiftyoneimagedetectiondataset)           | ✓                 | ✓                 | ✓                     |\n",
        "| [COCODetectionDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#cocodetectiondataset)                             | ✓                 | ✓                 | ✓                     |\n",
        "| [VOCDetectionDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#vocdetectiondataset)                               | ✓                 | ✓                 | ✓                     |\n",
        "| [KITTIDetectionDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#kittidetectiondataset)                           | ✓                 | ✓                 | ✓                     |\n",
        "| [YOLODataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#yolodataset)                                               | ✓                 | ✓                 | ✓                     |\n",
        "| [TFObjectDetectionDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#tfobjectdetectiondataset)                     | ✓                 | ✓                 | ✓                     |\n",
        "| [CVATImageDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#cvatimagedataset)                                     | ✓                 | ✓                 | ✓                     |\n",
        "| [CVATVideoDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#cvatvideodataset)                                     | ✓                 | ✓                 | ✓                     |\n",
        "| [FiftyOneImageLabelsDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#fiftyoneimagelabelsdataset)                 | ✓                 | ✓                 | ✓                     |\n",
        "| [FiftyOneVideoLabelsDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#fiftyonevideolabelsdataset)                 | ✓                 | ✓                 | ✓                     |\n",
        "| [BDDDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#bdddataset)                                                 | ✓                 | ✓                 | ✓                     |\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01TSCDVKHqUi"
      },
      "source": [
        "In addition, you can define your own [custom dataset types](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#custom-formats) to read/write datasets in your own formats.\n",
        "\n",
        "The usage of the `fiftyone convert` command is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W9Ca_MsPHqUi",
        "outputId": "0aeb3630-360a-4ef5-8517-5110f5769c89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: fiftyone convert [-h] --input-type INPUT_TYPE --output-type OUTPUT_TYPE\n",
            "                        [--input-dir INPUT_DIR]\n",
            "                        [--input-kwargs KEY=VAL [KEY=VAL ...]]\n",
            "                        [--output-dir OUTPUT_DIR]\n",
            "                        [--output-kwargs KEY=VAL [KEY=VAL ...]] [-o]\n",
            "\n",
            "Convert datasets on disk between supported formats.\n",
            "\n",
            "    Examples::\n",
            "\n",
            "        # Convert an image classification directory tree to TFRecords format\n",
            "        fiftyone convert \\\n",
            "            --input-dir /path/to/image-classification-directory-tree \\\n",
            "            --input-type fiftyone.types.ImageClassificationDirectoryTree \\\n",
            "            --output-dir /path/for/tf-image-classification-dataset \\\n",
            "            --output-type fiftyone.types.TFImageClassificationDataset\n",
            "\n",
            "        # Convert a COCO detection dataset to CVAT image format\n",
            "        fiftyone convert \\\n",
            "            --input-dir /path/to/coco-detection-dataset \\\n",
            "            --input-type fiftyone.types.COCODetectionDataset \\\n",
            "            --output-dir /path/for/cvat-image-dataset \\\n",
            "            --output-type fiftyone.types.CVATImageDataset\n",
            "\n",
            "        # Perform a customized conversion via optional kwargs\n",
            "        fiftyone convert \\\n",
            "            --input-dir /path/to/coco-detection-dataset \\\n",
            "            --input-type fiftyone.types.COCODetectionDataset \\\n",
            "            --input-kwargs max_samples=100 shuffle=True \\\n",
            "            --output-dir /path/for/cvat-image-dataset \\\n",
            "            --output-type fiftyone.types.TFObjectDetectionDataset \\\n",
            "            --output-kwargs force_rgb=True \\\n",
            "            --overwrite\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --input-dir INPUT_DIR\n",
            "                        the directory containing the dataset\n",
            "  --input-kwargs KEY=VAL [KEY=VAL ...]\n",
            "                        additional keyword arguments for `fiftyone.utils.data.convert_dataset(..., input_kwargs=)`\n",
            "  --output-dir OUTPUT_DIR\n",
            "                        the directory to which to write the output dataset\n",
            "  --output-kwargs KEY=VAL [KEY=VAL ...]\n",
            "                        additional keyword arguments for `fiftyone.utils.data.convert_dataset(..., output_kwargs=)`\n",
            "  -o, --overwrite       whether to overwrite an existing output directory\n",
            "\n",
            "required arguments:\n",
            "  --input-type INPUT_TYPE\n",
            "                        the fiftyone.types.Dataset type of the input dataset\n",
            "  --output-type OUTPUT_TYPE\n",
            "                        the fiftyone.types.Dataset type to output\n"
          ]
        }
      ],
      "source": [
        "!fiftyone convert -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVi81pViHqUi"
      },
      "source": [
        "## Convert CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3Qoh1IwHqUj"
      },
      "source": [
        "When you downloaded the test split of the CIFAR-10 dataset above, it was written to disk as a dataset in [fiftyone.types.FiftyOneImageClassificationDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#fiftyoneimageclassificationdataset) format.\n",
        "\n",
        "You can verify this by printing information about the downloaded dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxxPowRBHqUj"
      },
      "outputs": [],
      "source": [
        "!fiftyone zoo datasets info /content/annotations_9may"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/annotations_9may.zip"
      ],
      "metadata": {
        "id": "xWHxiCqrIV0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef1LrclwHqUj"
      },
      "source": [
        "The snippet below uses `fiftyone convert` to convert the test split of the CIFAR-10 dataset to [fiftyone.types.ImageClassificationDirectoryTree](https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html#imageclassificationdirectorytree) format, which stores classification datasets on disk in a directory tree structure with images organized per-class:\n",
        "\n",
        "```\n",
        "<dataset_dir>\n",
        "├── <classA>/\n",
        "│   ├── <image1>.<ext>\n",
        "│   ├── <image2>.<ext>\n",
        "│   └── ...\n",
        "├── <classB>/\n",
        "│   ├── <image1>.<ext>\n",
        "│   ├── <image2>.<ext>\n",
        "│   └── ...\n",
        "└── ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, fnmatch\n",
        "import numpy as np\n",
        "\n",
        "# + то же самое для файла с train\n",
        "valid_file = open(\"/content/valid.txt\", \"w\")\n",
        "listOfFiles = os.listdir('/content/annotations_9may')\n",
        "print(listOfFiles)\n",
        "for f_name in listOfFiles:\n",
        "  if fnmatch.fnmatch(f_name, \"*.jpg\"):\n",
        "      valid_file.write(\"/content/annotations_9may/\"+f_name+\"\\n\")\n",
        "  if fnmatch.fnmatch(f_name, \"*.png\"):\n",
        "      valid_file.write(\"/content/annotations_9may/\"+f_name+\"\\n\")\n",
        "\n",
        "valid_file.close()"
      ],
      "metadata": {
        "id": "dcWaeRpWKSCE",
        "outputId": "4cc2558c-abe9-4148-abeb-1c6894640090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['22368-Салмани_Ариан_-0.jpg', '22344-Ghobadi_Mahdi_-1.jpg', '22384-None_GYF_-2.txt', '22323-None_Daniyar_-1.jpg', '22438-Копанева_Кристина_-2.txt', '22445-Макарова_Мария_-2.txt', '22387-None_Rsprspr_-0.jpg', '22383-Салмани_Ариан_-1.txt', '22310-None_Данил_-2.txt', '22345-None_Бахар_-0.jpg', '22311-Bikmullin_Amir_-2.txt', '22406-None_Дякунесса_-0.txt', '22419-None_Damir_-0.txt', '22416-None_ARK_-2.txt', '22341-None_Радин_-1.txt', '22311-Bikmullin_Amir_-1.txt', '22336-None_Бахар_-1.jpg', '22421-None_Etreamoi_-0.jpg', '22342-None_Радин_-2.jpg', '22415-None_None_-2.txt', '22413-None_Dilyara_-0.jpg', '22391-Vahitov_Bulat_-0.txt', '22368-Салмани_Ариан_-2.jpg', '22391-Vahitov_Bulat_-0.jpg', '22388-None_ARK_-2.jpg', '22393-None_._-0.txt', '22452-None_Кирилл_-1.jpg', '22335-Шарафеев_Руслан_-2.txt', '22427-ㅤ_self_hugs_-1.txt', '22321-Ostapenko_Maks_-1.txt', '22439-Киселева_Дарина_-1.txt', '22400-None_макс_-0.txt', '22329-Валиева_Камиля_-2.jpg', '22447-N_I_-1.jpg', '22377-None_ARK_-0.jpg', '22433-Салмани_Ариан_-2.jpg', '22438-Копанева_Кристина_-0.txt', '22448-None_макс_-0.jpg', '22379-Осипов_Илья_-0.txt', '22347-Аитов_Дамир_-0.txt', '22334-None_Helena_-1.jpg', '22420-None_Etreamoi_-0.jpg', '22322-None_Daniyar_-0.txt', '22406-None_Дякунесса_-2.jpg', '22316-Абдуллин_Рауль_-2.jpg', '22341-None_Радин_-0.jpg', '22449-Истомин_Юрий_Александрович-0.jpg', '22423-None_Али_-1.jpg', '22443-Осипов_Илья_-0.txt', '22325-None_Эльдар_-1.txt', '22435-Yusupov_Adel_-0.txt', '22450-Shagalikhanov_Renar_Firdavisovich_-1.txt', '22393-None_._-1.jpg', '22386-None_ARK_-0.txt', '22433-Салмани_Ариан_-0.txt', '22340-Fazylov_Marat_-2.jpg', '22433-Салмани_Ариан_-1.jpg', '22312-Bikmullin_Amir_-1.jpg', '22336-None_Бахар_-2.txt', '22326-None_Эльдар_-1.txt', '22310-None_Данил_-0.jpg', '22373-None_Daniyar_-1.txt', '22377-None_ARK_-0.txt', '22409-None_Артур_-2.jpg', '22384-None_GYF_-1.jpg', '22448-None_макс_-0.txt', '22409-None_Артур_-0.txt', '22407-None_Данил_-2.jpg', '22321-Ostapenko_Maks_-0.txt', '22343-None_Rsprspr_-2.jpg', '22380-Эс_Х_-2.txt', '22435-Yusupov_Adel_-2.jpg', '22383-Салмани_Ариан_-2.txt', '22444-Спиридонова_Валерия_-1.txt', '22410-_Drahar_Moonstone__Max_Zelenyuk__-2.jpg', '22395-Fazylov_Marat_-1.jpg', '22396-Куликов_Александр_-2.txt', '22446-Копанева_Кристина_-1.txt', '22326-None_Эльдар_-2.txt', '22382-__𝑚𝑎𝑡𝑖𝑛..._-2.jpg', '22388-None_ARK_-1.jpg', '22391-Vahitov_Bulat_-1.txt', '22392-None_Ramil_-1.txt', '22443-Осипов_Илья_-2.jpg', '22368-Салмани_Ариан_-0.txt', '22450-Shagalikhanov_Renar_Firdavisovich_-1.jpg', '22326-None_Эльдар_-0.txt', '22429-_Young_Timur_-1.jpg', '22448-None_макс_-2.jpg', '22333-Осипов_Илья_-0.txt', '22421-None_Etreamoi_-2.txt', '22434-None_Иван_-0.txt', '22380-Эс_Х_-1.jpg', '22416-None_ARK_-2.jpg', '22419-None_Damir_-1.txt', '22334-None_Helena_-0.txt', '22367-Абдуллин_Рауль_-1.txt', '22409-None_Артур_-1.jpg', '22422-Салмани_Ариан_-2.txt', '22392-None_Ramil_-0.txt', '22380-Эс_Х_-0.txt', '22397-Макарова_Мария_-1.jpg', '22403-None_Denis_-1.jpg', '22445-Макарова_Мария_-1.txt', '22410-_Drahar_Moonstone__Max_Zelenyuk__-1.txt', '22314-норас_садра_-0.jpg', '22419-None_Damir_-0.jpg', '22316-Абдуллин_Рауль_-1.jpg', '22433-Салмани_Ариан_-0.jpg', '22417-Осипов_Илья_-1.txt', '22378-Салмани_Ариан_-0.jpg', '22366-Абдуллин_Рауль_-0.jpg', '22312-Bikmullin_Amir_-1.txt', '22406-None_Дякунесса_-2.txt', '22321-Ostapenko_Maks_-1.jpg', '22392-None_Ramil_-2.jpg', '22389-Копанева_Кристина_-1.jpg', '22441-None_Миланочка_Ким_-2.jpg', '22434-None_Иван_-0.jpg', '22421-None_Etreamoi_-1.jpg', '22324-Абрамов_Алексей_Михайлович-0.txt', '22333-Осипов_Илья_-0.jpg', '.DS_Store', '22388-None_ARK_-1.txt', '22393-None_._-2.jpg', '22444-Спиридонова_Валерия_-2.txt', '22347-Аитов_Дамир_-2.jpg', '22419-None_Damir_-1.jpg', '22324-Абрамов_Алексей_Михайлович-1.jpg', '22429-_Young_Timur_-2.txt', '22314-норас_садра_-2.txt', '22377-None_ARK_-1.jpg', '22387-None_Rsprspr_-2.jpg', '22337-None_Helena_-1.txt', '22366-Абдуллин_Рауль_-1.jpg', '22314-норас_садра_-1.txt', '22365-Абдуллин_Рауль_-1.jpg', '22396-Куликов_Александр_-0.jpg', '22365-Абдуллин_Рауль_-0.txt', '22405-Осипов_Илья_-0.jpg', '22421-None_Etreamoi_-2.jpg', '22311-Bikmullin_Amir_-2.jpg', '22435-Yusupov_Adel_-1.txt', '22383-Салмани_Ариан_-2.jpg', '22415-None_None_-1.jpg', '22390-None_Иван_-2.jpg', '22335-Шарафеев_Руслан_-1.jpg', '22311-Bikmullin_Amir_-1.jpg', '22401-None_Кирилл_-1.jpg', '22366-Абдуллин_Рауль_-2.jpg', '22401-None_Кирилл_-2.txt', '22433-Салмани_Ариан_-2.txt', '22338-Хузеев_Марат_Иршатович-1.txt', '22346-None_ARK_-1.txt', '22441-None_Миланочка_Ким_-1.txt', '22394-None_Павел_Давыдов_-2.txt', '22339-None_Negin_-0.jpg', '22312-Bikmullin_Amir_-0.jpg', '22338-Хузеев_Марат_Иршатович-0.jpg', '22368-Салмани_Ариан_-1.txt', '22343-None_Rsprspr_-1.jpg', '22327-None_Salavat_G._-2.jpg', '22378-Салмани_Ариан_-1.jpg', '22395-Fazylov_Marat_-0.jpg', '22427-ㅤ_self_hugs_-0.txt', '22379-Осипов_Илья_-1.jpg', '22447-N_I_-2.txt', '22380-Эс_Х_-0.jpg', '22339-None_Negin_-1.jpg', '22394-None_Павел_Давыдов_-2.jpg', '22338-Хузеев_Марат_Иршатович-2.txt', '22345-None_Бахар_-0.txt', '22340-Fazylov_Marat_-0.txt', '22438-Копанева_Кристина_-1.jpg', '22339-None_Negin_-2.txt', '22407-None_Данил_-2.txt', '22341-None_Радин_-1.jpg', '22389-Копанева_Кристина_-0.jpg', '22404-None_Garipov_-0.txt', '22344-Ghobadi_Mahdi_-1.txt', '22413-None_Dilyara_-2.txt', '22386-None_ARK_-0.jpg', '22407-None_Данил_-0.jpg', '22334-None_Helena_-0.jpg', '22339-None_Negin_-0.txt', '22416-None_ARK_-0.jpg', '22323-None_Daniyar_-2.txt', '22422-Салмани_Ариан_-1.txt', '22378-Салмани_Ариан_-2.txt', '22384-None_GYF_-0.jpg', '22337-None_Helena_-1.jpg', '22313-None_Emilien_-1.txt', '22423-None_Али_-0.txt', '22335-Шарафеев_Руслан_-0.jpg', '22382-__𝑚𝑎𝑡𝑖𝑛..._-0.jpg', '22400-None_макс_-2.txt', '22444-Спиридонова_Валерия_-0.jpg', '22340-Fazylov_Marat_-0.jpg', '22422-Салмани_Ариан_-2.jpg', '22380-Эс_Х_-2.jpg', '22314-норас_садра_-0.txt', '22314-норас_садра_-2.jpg', '22410-_Drahar_Moonstone__Max_Zelenyuk__-1.jpg', '22393-None_._-1.txt', '22391-Vahitov_Bulat_-2.jpg', '22434-None_Иван_-1.jpg', '22414-None_ARK_-0.txt', '22377-None_ARK_-2.jpg', '22345-None_Бахар_-1.jpg', '22367-Абдуллин_Рауль_-0.jpg', '22312-Bikmullin_Amir_-2.jpg', '22420-None_Etreamoi_-1.jpg', '22438-Копанева_Кристина_-0.jpg', '22450-Shagalikhanov_Renar_Firdavisovich_-2.txt', '22323-None_Daniyar_-0.txt', '22443-Осипов_Илья_-1.jpg', '22384-None_GYF_-1.txt', '22436-Vahitov_Bulat_-2.jpg', '22322-None_Daniyar_-1.jpg', '22449-Истомин_Юрий_Александрович-2.txt', '22406-None_Дякунесса_-1.txt', '22338-Хузеев_Марат_Иршатович-0.txt', '22396-Куликов_Александр_-1.txt', '22392-None_Ramil_-0.jpg', '22423-None_Али_-0.jpg', '22425-None_U2606_-0.txt', '22439-Киселева_Дарина_-2.jpg', '22329-Валиева_Камиля_-1.jpg', '22450-Shagalikhanov_Renar_Firdavisovich_-0.jpg', '22340-Fazylov_Marat_-1.txt', '22440-None_Adelya_Ahmadieva_-1.txt', '22347-Аитов_Дамир_-2.txt', '22446-Копанева_Кристина_-0.jpg', '22323-None_Daniyar_-1.txt', '22347-Аитов_Дамир_-1.txt', '22389-Копанева_Кристина_-0.txt', '22336-None_Бахар_-0.jpg', '22330-None_Бахар_-0.txt', '22446-Копанева_Кристина_-2.jpg', '22384-None_GYF_-0.txt', '22423-None_Али_-2.jpg', '22414-None_ARK_-1.jpg', '22325-None_Эльдар_-2.jpg', '22429-_Young_Timur_-0.jpg', '22414-None_ARK_-2.txt', '22401-None_Кирилл_-0.txt', '22440-None_Adelya_Ahmadieva_-1.jpg', '22328-None_Salavat_G._-2.txt', '22413-None_Dilyara_-1.txt', '22335-Шарафеев_Руслан_-1.txt', '22310-None_Данил_-1.jpg', '22434-None_Иван_-2.txt', '22394-None_Павел_Давыдов_-1.txt', '22366-Абдуллин_Рауль_-2.txt', '22447-N_I_-2.jpg', '22365-Абдуллин_Рауль_-1.txt', '22379-Осипов_Илья_-1.txt', '22313-None_Emilien_-1.jpg', '22390-None_Иван_-1.txt', '22444-Спиридонова_Валерия_-0.txt', '22347-Аитов_Дамир_-0.jpg', '22379-Осипов_Илья_-0.jpg', '22403-None_Denis_-1.txt', '22333-Осипов_Илья_-1.txt', '22382-__𝑚𝑎𝑡𝑖𝑛..._-2.txt', '22313-None_Emilien_-0.txt', '22405-Осипов_Илья_-2.jpg', '22402-Абрамов_Алексей_Михайлович-2.jpg', '22328-None_Salavat_G._-1.txt', '22400-None_макс_-2.jpg', '22447-N_I_-0.txt', '22439-Киселева_Дарина_-2.txt', '22324-Абрамов_Алексей_Михайлович-2.jpg', '22429-_Young_Timur_-2.jpg', '22346-None_ARK_-0.txt', '22417-Осипов_Илья_-2.jpg', '22446-Копанева_Кристина_-1.jpg', '22392-None_Ramil_-2.txt', '22387-None_Rsprspr_-0.txt', '22324-Абрамов_Алексей_Михайлович-1.txt', '22343-None_Rsprspr_-0.txt', '22425-None_U2606_-0.jpg', '22441-None_Миланочка_Ким_-2.txt', '22326-None_Эльдар_-2.jpg', '22404-None_Garipov_-2.jpg', '22436-Vahitov_Bulat_-0.txt', '22401-None_Кирилл_-1.txt', '22355-Осипов_Илья_-0.jpg', '22452-None_Кирилл_-2.jpg', '22373-None_Daniyar_-2.jpg', '22390-None_Иван_-0.jpg', '22346-None_ARK_-2.jpg', '22321-Ostapenko_Maks_-0.jpg', '22387-None_Rsprspr_-1.jpg', '22405-Осипов_Илья_-2.txt', '22376-Daminov_Albert_-2.txt', '22397-Макарова_Мария_-1.txt', '22342-None_Радин_-1.jpg', '22378-Салмани_Ариан_-1.txt', '22365-Абдуллин_Рауль_-2.jpg', '22437-М_Камиль_-2.jpg', '22437-М_Камиль_-1.txt', '22322-None_Daniyar_-2.jpg', '22452-None_Кирилл_-2.txt', '22415-None_None_-0.jpg', '22389-Копанева_Кристина_-1.txt', '22368-Салмани_Ариан_-2.txt', '22330-None_Бахар_-0.jpg', '22378-Салмани_Ариан_-0.txt', '22417-Осипов_Илья_-0.txt', '22443-Осипов_Илья_-2.txt', '22325-None_Эльдар_-2.txt', '22395-Fazylov_Marat_-1.txt', '22449-Истомин_Юрий_Александрович-1.txt', '22330-None_Бахар_-1.txt', '22427-ㅤ_self_hugs_-1.jpg', '22420-None_Etreamoi_-2.txt', '22406-None_Дякунесса_-1.jpg', '22403-None_Denis_-0.jpg', '22337-None_Helena_-0.jpg', '22375-Bikmullin_Amir_-0.txt', '22342-None_Радин_-0.jpg', '22366-Абдуллин_Рауль_-1.txt', '22440-None_Adelya_Ahmadieva_-2.jpg', '22420-None_Etreamoi_-2.jpg', '22448-None_макс_-1.jpg', '22327-None_Salavat_G._-0.txt', '22395-Fazylov_Marat_-2.jpg', '22334-None_Helena_-2.txt', '22313-None_Emilien_-2.txt', '22377-None_ARK_-1.txt', '22444-Спиридонова_Валерия_-1.jpg', '22339-None_Negin_-1.txt', '22344-Ghobadi_Mahdi_-2.jpg', '22415-None_None_-2.jpg', '22407-None_Данил_-1.txt', '22425-None_U2606_-1.jpg', '22389-Копанева_Кристина_-2.jpg', '22427-ㅤ_self_hugs_-0.jpg', '22322-None_Daniyar_-2.txt', '22415-None_None_-1.txt', '22434-None_Иван_-2.jpg', '22416-None_ARK_-0.txt', '22376-Daminov_Albert_-0.jpg', '22396-Куликов_Александр_-2.jpg', '22410-_Drahar_Moonstone__Max_Zelenyuk__-0.jpg', '22446-Копанева_Кристина_-2.txt', '22422-Салмани_Ариан_-0.txt', '22406-None_Дякунесса_-0.jpg', '22437-М_Камиль_-2.txt', '22397-Макарова_Мария_-2.txt', '22397-Макарова_Мария_-0.txt', '22336-None_Бахар_-1.txt', '22422-Салмани_Ариан_-1.jpg', '22321-Ostapenko_Maks_-2.jpg', '22452-None_Кирилл_-0.jpg', '22394-None_Павел_Давыдов_-1.jpg', '22375-Bikmullin_Amir_-0.jpg', '22421-None_Etreamoi_-1.txt', '22419-None_Damir_-2.txt', '22425-None_U2606_-2.jpg', '22322-None_Daniyar_-0.jpg', '22335-Шарафеев_Руслан_-2.jpg', '22407-None_Данил_-0.txt', '22400-None_макс_-1.jpg', '22342-None_Радин_-1.txt', '22404-None_Garipov_-1.txt', '22445-Макарова_Мария_-0.jpg', '22334-None_Helena_-2.jpg', '22316-Абдуллин_Рауль_-0.txt', '22414-None_ARK_-0.jpg', '22376-Daminov_Albert_-2.jpg', '22417-Осипов_Илья_-2.txt', '22402-Абрамов_Алексей_Михайлович-1.jpg', '22386-None_ARK_-2.txt', '22400-None_макс_-1.txt', '22327-None_Salavat_G._-1.txt', '22435-Yusupov_Adel_-2.txt', '22404-None_Garipov_-0.jpg', '22386-None_ARK_-2.jpg', '22427-ㅤ_self_hugs_-2.jpg', '22409-None_Артур_-1.txt', '22405-Осипов_Илья_-1.jpg', '22375-Bikmullin_Amir_-1.txt', '22379-Осипов_Илья_-2.jpg', '22340-Fazylov_Marat_-1.jpg', '22343-None_Rsprspr_-0.jpg', '22438-Копанева_Кристина_-2.jpg', '22423-None_Али_-1.txt', '22420-None_Etreamoi_-0.txt', '22347-Аитов_Дамир_-1.jpg', '22341-None_Радин_-0.txt', '22367-Абдуллин_Рауль_-0.txt', '22449-Истомин_Юрий_Александрович-1.jpg', '22325-None_Эльдар_-0.txt', '22342-None_Радин_-0.txt', '22330-None_Бахар_-2.jpg', '22345-None_Бахар_-2.txt', '22429-_Young_Timur_-1.txt', '22330-None_Бахар_-2.txt', '22413-None_Dilyara_-0.txt', '22395-Fazylov_Marat_-0.txt', '22345-None_Бахар_-1.txt', '22383-Салмани_Ариан_-0.jpg', '22393-None_._-2.txt', '22390-None_Иван_-1.jpg', '22310-None_Данил_-1.txt', '22436-Vahitov_Bulat_-2.txt', '22326-None_Эльдар_-0.jpg', '22355-Осипов_Илья_-0.txt', '22447-N_I_-1.txt', '22324-Абрамов_Алексей_Михайлович-0.jpg', '22324-Абрамов_Алексей_Михайлович-2.txt', '22405-Осипов_Илья_-1.txt', '22394-None_Павел_Давыдов_-0.jpg', '22450-Shagalikhanov_Renar_Firdavisovich_-0.txt', '22329-Валиева_Камиля_-0.txt', '22355-Осипов_Илья_-2.jpg', '22325-None_Эльдар_-1.jpg', '22329-Валиева_Камиля_-1.txt', '22316-Абдуллин_Рауль_-0.jpg', '22416-None_ARK_-1.txt', '22402-Абрамов_Алексей_Михайлович-2.txt', '22443-Осипов_Илья_-0.jpg', '22403-None_Denis_-2.jpg', '22343-None_Rsprspr_-2.txt', '22328-None_Salavat_G._-1.jpg', '22425-None_U2606_-1.txt', '22380-Эс_Х_-1.txt', '22373-None_Daniyar_-0.jpg', '22415-None_None_-0.txt', '22331-None_Жасур_-0.jpg', '22417-Осипов_Илья_-0.jpg', '22327-None_Salavat_G._-1.jpg', '22397-Макарова_Мария_-0.jpg', '22437-М_Камиль_-1.jpg', '22416-None_ARK_-1.jpg', '22367-Абдуллин_Рауль_-2.txt', '22325-None_Эльдар_-0.jpg', '22423-None_Али_-2.txt', '22336-None_Бахар_-2.jpg', '22410-_Drahar_Moonstone__Max_Zelenyuk__-2.txt', '22345-None_Бахар_-2.jpg', '22441-None_Миланочка_Ким_-1.jpg', '22366-Абдуллин_Рауль_-0.txt', '22322-None_Daniyar_-1.txt', '22441-None_Миланочка_Ким_-0.txt', '22391-Vahitov_Bulat_-2.txt', '22448-None_макс_-2.txt', '22329-Валиева_Камиля_-0.jpg', '22344-Ghobadi_Mahdi_-0.txt', '22331-None_Жасур_-2.txt', '22312-Bikmullin_Amir_-0.txt', '22333-Осипов_Илья_-2.jpg', '22339-None_Negin_-2.jpg', '22449-Истомин_Юрий_Александрович-2.jpg', '22409-None_Артур_-2.txt', '22386-None_ARK_-1.txt', '22328-None_Salavat_G._-0.jpg', '22313-None_Emilien_-0.jpg', '22402-Абрамов_Алексей_Михайлович-1.txt', '22312-Bikmullin_Amir_-2.txt', '22343-None_Rsprspr_-1.txt', '22373-None_Daniyar_-2.txt', '22377-None_ARK_-2.txt', '22337-None_Helena_-2.jpg', '22437-М_Камиль_-0.txt', '22397-Макарова_Мария_-2.jpg', '22439-Киселева_Дарина_-0.jpg', '22323-None_Daniyar_-0.jpg', '22396-Куликов_Александр_-1.jpg', '22335-Шарафеев_Руслан_-0.txt', '22375-Bikmullin_Amir_-1.jpg', '22331-None_Жасур_-2.jpg', '22337-None_Helena_-2.txt', '22384-None_GYF_-2.jpg', '22440-None_Adelya_Ahmadieva_-2.txt', '22340-Fazylov_Marat_-2.txt', '22407-None_Данил_-1.jpg', '22389-Копанева_Кристина_-2.txt', '22402-Абрамов_Алексей_Михайлович-0.jpg', '22401-None_Кирилл_-2.jpg', '22435-Yusupov_Adel_-0.jpg', '22327-None_Salavat_G._-0.jpg', '22333-Осипов_Илья_-2.txt', '22367-Абдуллин_Рауль_-1.jpg', '22402-Абрамов_Алексей_Михайлович-0.txt', '22387-None_Rsprspr_-1.txt', '22435-Yusupov_Adel_-1.jpg', '22314-норас_садра_-1.jpg', '22445-Макарова_Мария_-2.jpg', '22344-Ghobadi_Mahdi_-2.txt', '22383-Салмани_Ариан_-1.jpg', '22376-Daminov_Albert_-1.txt', '22382-__𝑚𝑎𝑡𝑖𝑛..._-1.jpg', '22326-None_Эльдар_-1.jpg', '22387-None_Rsprspr_-2.txt', '22331-None_Жасур_-1.txt', '22321-Ostapenko_Maks_-2.txt', '22311-Bikmullin_Amir_-0.jpg', '22417-Осипов_Илья_-1.jpg', '22429-_Young_Timur_-0.txt', '22338-Хузеев_Марат_Иршатович-2.jpg', '22396-Куликов_Александр_-0.txt', '22375-Bikmullin_Amir_-2.jpg', '22382-__𝑚𝑎𝑡𝑖𝑛..._-0.txt', '22403-None_Denis_-0.txt', '22328-None_Salavat_G._-2.jpg', '22439-Киселева_Дарина_-0.txt', '22441-None_Миланочка_Ким_-0.jpg', '22334-None_Helena_-1.txt', '22409-None_Артур_-0.jpg', '22444-Спиридонова_Валерия_-2.jpg', '22376-Daminov_Albert_-0.txt', '22328-None_Salavat_G._-0.txt', '22375-Bikmullin_Amir_-2.txt', '22422-Салмани_Ариан_-0.jpg', '22316-Абдуллин_Рауль_-1.txt', '22420-None_Etreamoi_-1.txt', '22355-Осипов_Илья_-2.txt', '22373-None_Daniyar_-1.jpg', '22393-None_._-0.jpg', '22395-Fazylov_Marat_-2.txt', '22316-Абдуллин_Рауль_-2.txt', '22404-None_Garipov_-2.txt', '22436-Vahitov_Bulat_-1.txt', '22443-Осипов_Илья_-1.txt', '22427-ㅤ_self_hugs_-2.txt', '22413-None_Dilyara_-1.jpg', '22313-None_Emilien_-2.jpg', '22390-None_Иван_-0.txt', '22437-М_Камиль_-0.jpg', '22336-None_Бахар_-0.txt', '22388-None_ARK_-0.jpg', '22310-None_Данил_-0.txt', '22436-Vahitov_Bulat_-0.jpg', '22445-Макарова_Мария_-0.txt', '22365-Абдуллин_Рауль_-2.txt', '22344-Ghobadi_Mahdi_-0.jpg', '22446-Копанева_Кристина_-0.txt', '22447-N_I_-0.jpg', '22410-_Drahar_Moonstone__Max_Zelenyuk__-0.txt', '22436-Vahitov_Bulat_-1.jpg', '22346-None_ARK_-1.jpg', '22355-Осипов_Илья_-1.txt', '22450-Shagalikhanov_Renar_Firdavisovich_-2.jpg', '22378-Салмани_Ариан_-2.jpg', '22383-Салмани_Ариан_-0.txt', '22391-Vahitov_Bulat_-1.jpg', '22388-None_ARK_-0.txt', '22400-None_макс_-0.jpg', '22449-Истомин_Юрий_Александрович-0.txt', '22434-None_Иван_-1.txt', '22367-Абдуллин_Рауль_-2.jpg', '22448-None_макс_-1.txt', '22440-None_Adelya_Ahmadieva_-0.txt', '22376-Daminov_Albert_-1.jpg', '22327-None_Salavat_G._-2.txt', '22342-None_Радин_-2.txt', '22414-None_ARK_-1.txt', '22331-None_Жасур_-0.txt', '22311-Bikmullin_Amir_-0.txt', '22419-None_Damir_-2.jpg', '22386-None_ARK_-1.jpg', '22341-None_Радин_-2.jpg', '22379-Осипов_Илья_-2.txt', '22445-Макарова_Мария_-1.jpg', '22452-None_Кирилл_-0.txt', '22337-None_Helena_-0.txt', '22346-None_ARK_-0.jpg', '22390-None_Иван_-2.txt', '22333-Осипов_Илья_-1.jpg', '22425-None_U2606_-2.txt', '22438-Копанева_Кристина_-1.txt', '22323-None_Daniyar_-2.jpg', '22331-None_Жасур_-1.jpg', '22355-Осипов_Илья_-1.jpg', '22388-None_ARK_-2.txt', '22440-None_Adelya_Ahmadieva_-0.jpg', '22404-None_Garipov_-1.jpg', '22403-None_Denis_-2.txt', '22373-None_Daniyar_-0.txt', '22392-None_Ramil_-1.jpg', '22433-Салмани_Ариан_-1.txt', '22382-__𝑚𝑎𝑡𝑖𝑛..._-1.txt', '22310-None_Данил_-2.jpg', '22346-None_ARK_-2.txt', '22341-None_Радин_-2.txt', '22439-Киселева_Дарина_-1.jpg', '22329-Валиева_Камиля_-2.txt', '22414-None_ARK_-2.jpg', '22413-None_Dilyara_-2.jpg', '22421-None_Etreamoi_-0.txt', '22338-Хузеев_Марат_Иршатович-1.jpg', '22368-Салмани_Ариан_-1.jpg', '22452-None_Кирилл_-1.txt', '22365-Абдуллин_Рауль_-0.jpg', '22401-None_Кирилл_-0.jpg', '22394-None_Павел_Давыдов_-0.txt', '22405-Осипов_Илья_-0.txt', '22330-None_Бахар_-1.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HhALpkOjHqUj",
        "outputId": "2ff94bb9-6dfc-4870-ccfb-a44c19f1b0c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using input format: fiftyone.types.dataset_types.YOLOv4Dataset\n",
            "Using export format: fiftyone.types.dataset_types.COCODetectionDataset\n",
            "Loading dataset from '/content/annotations_9may'\n",
            "Images file '/content/annotations_9may/images.txt' not found. Listing data directory '/content/annotations_9may/data/' instead\n",
            "\r\r\r\r\r\r\n",
            "Exporting dataset to '/content/annotations_9may_COCO'\n",
            "Directory '/content/annotations_9may_COCO' already exists; export will be merged with existing files\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fiftyone\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/core/cli.py\", line 4793, in main\n",
            "    args.execute(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/core/cli.py\", line 4776, in <lambda>\n",
            "    parser.set_defaults(execute=lambda args: command.execute(parser, args))\n",
            "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/core/cli.py\", line 371, in execute\n",
            "    foud.convert_dataset(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/utils/data/converters.py\", line 135, in convert_dataset\n",
            "    dataset.export(dataset_exporter=dataset_exporter, overwrite=overwrite)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/core/collections.py\", line 9566, in export\n",
            "    _export(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/core/collections.py\", line 12286, in _export\n",
            "    label_field = sample_collection._parse_label_field(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/core/collections.py\", line 11069, in _parse_label_field\n",
            "    return _parse_label_field(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/core/collections.py\", line 11547, in _parse_label_field\n",
            "    label_field = _get_default_label_fields_for_exporter(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/core/collections.py\", line 11662, in _get_default_label_fields_for_exporter\n",
            "    raise ValueError(\n",
            "ValueError: No compatible field(s) of type (<class 'fiftyone.core.labels.Detections'>, <class 'fiftyone.core.labels.Polylines'>, <class 'fiftyone.core.labels.Keypoints'>) found\n"
          ]
        }
      ],
      "source": [
        "!fiftyone convert \\\n",
        "    --input-dir /content/annotations_9may --input-type fiftyone.types.YOLOv4Dataset \\\n",
        "    --output-dir /content/annotations_9may_COCO --output-type fiftyone.types.COCODetectionDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llJaclyAHqUj"
      },
      "source": [
        "Let's verify that the conversion happened as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR-0WrQgHqUj",
        "outputId": "6f88891a-10df-4085-aac2-86ec97480fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 0\n",
            "drwxr-xr-x    12 voxel51  wheel   384B Jul 14 11:08 .\n",
            "drwxr-xr-x     3 voxel51  wheel    96B Jul 14 11:08 ..\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 airplane\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 automobile\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 bird\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 cat\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 deer\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 dog\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 frog\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 horse\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 ship\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 truck\n"
          ]
        }
      ],
      "source": [
        "ls -lah /tmp/fiftyone/cifar10-dir-tree/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY9dB8v6HqUj",
        "outputId": "7a63fe90-86e7-4309-e349-da2508811820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 8000\n",
            "drwxr-xr-x  1002 voxel51  wheel    31K Jul 14 11:08 .\n",
            "drwxr-xr-x    12 voxel51  wheel   384B Jul 14 11:08 ..\n",
            "-rw-r--r--     1 voxel51  wheel   1.2K Jul 14 11:23 000004.jpg\n",
            "-rw-r--r--     1 voxel51  wheel   1.1K Jul 14 11:23 000011.jpg\n",
            "-rw-r--r--     1 voxel51  wheel   1.1K Jul 14 11:23 000022.jpg\n",
            "-rw-r--r--     1 voxel51  wheel   1.3K Jul 14 11:23 000028.jpg\n",
            "-rw-r--r--     1 voxel51  wheel   1.2K Jul 14 11:23 000045.jpg\n",
            "-rw-r--r--     1 voxel51  wheel   1.2K Jul 14 11:23 000053.jpg\n",
            "-rw-r--r--     1 voxel51  wheel   1.3K Jul 14 11:23 000075.jpg\n"
          ]
        }
      ],
      "source": [
        "ls -lah /tmp/fiftyone/cifar10-dir-tree/airplane/ | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLlhDokYHqUj"
      },
      "source": [
        "Now let's convert the classification directory tree to [TFRecords](https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html#tfimageclassificationdataset) format!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TemOhI9WHqUj",
        "outputId": "cec5561a-5d2c-4310-c658-a344616aa300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from '/tmp/fiftyone/cifar10-dir-tree'\n",
            "Input format 'fiftyone.types.dataset_types.ImageClassificationDirectoryTree'\n",
            " 100% |███| 10000/10000 [4.0s elapsed, 0s remaining, 2.5K samples/s]      \n",
            "Import complete\n",
            "Exporting dataset to '/tmp/fiftyone/cifar10-tfrecords'\n",
            "Export format 'fiftyone.types.dataset_types.TFImageClassificationDataset'\n",
            "   0% ||--|     1/10000 [23.2ms elapsed, 3.9m remaining, 43.2 samples/s] 2020-07-14 11:24:15.187387: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-07-14 11:24:15.201384: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83df428f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-14 11:24:15.201405: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            " 100% |███| 10000/10000 [8.2s elapsed, 0s remaining, 1.3K samples/s]        \n",
            "Export complete\n"
          ]
        }
      ],
      "source": [
        "INPUT_DIR=/content/annotations_9may\n",
        "OUTPUT_DIR=/content/annotations_9may_COCO\n",
        "\n",
        "fiftyone convert \\\n",
        "    --input-dir ${INPUT_DIR} --input-type fiftyone.types.ImageClassificationDirectoryTree \\\n",
        "    --output-dir ${OUTPUT_DIR} --output-type fiftyone.types.TFImageClassificationDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHTQJB6AHqUj"
      },
      "source": [
        "Let's verify that the conversion happened as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "im0VJipqHqUj",
        "outputId": "e657067b-bde4-49ed-988a-7947145e82fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 29696\n",
            "drwxr-xr-x  3 voxel51  wheel    96B Jul 14 11:24 .\n",
            "drwxr-xr-x  4 voxel51  wheel   128B Jul 14 11:24 ..\n",
            "-rw-r--r--  1 voxel51  wheel    14M Jul 14 11:24 tf.records\n"
          ]
        }
      ],
      "source": [
        "ls -lah /tmp/fiftyone/cifar10-tfrecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snI3uy8HHqUj"
      },
      "source": [
        "## Convert KITTI dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JApIFgYjHqUj"
      },
      "source": [
        "When you downloaded the validation split of the KITTI dataset above, it was written to disk as a dataset in [fiftyone.types.FiftyOneImageDetectionDataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#fiftyoneimagedetectiondataset) format.\n",
        "\n",
        "You can verify this by printing information about the downloaded dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afm-8NG7HqUj",
        "outputId": "8671d082-6c1b-4127-eacb-31cb3fbb493f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***** Dataset description *****\n",
            "KITTI contains a suite of vision tasks built using an autonomous\n",
            "    driving platform.\n",
            "\n",
            "    The full benchmark contains many tasks such as stereo, optical flow, visual\n",
            "    odometry, etc. This dataset contains the object detection dataset,\n",
            "    including the monocular images and bounding boxes. The dataset contains\n",
            "    7481 training images annotated with 3D bounding boxes. A full description\n",
            "    of the annotations can be found in the README of the object development kit\n",
            "    on the KITTI homepage.\n",
            "\n",
            "    Dataset size:\n",
            "        5.27 GiB\n",
            "\n",
            "    Source:\n",
            "        http://www.cvlibs.net/datasets/kitti\n",
            "    \n",
            "***** Supported splits *****\n",
            "test, train, validation\n",
            "\n",
            "***** Dataset location *****\n",
            "~/fiftyone/kitti\n",
            "\n",
            "***** Dataset info *****\n",
            "{\n",
            "    \"name\": \"kitti\",\n",
            "    \"zoo_dataset\": \"fiftyone.zoo.datasets.tf.KITTIDataset\",\n",
            "    \"dataset_type\": \"fiftyone.types.dataset_types.FiftyOneImageDetectionDataset\",\n",
            "    \"num_samples\": 423,\n",
            "    \"downloaded_splits\": {\n",
            "        \"validation\": {\n",
            "            \"split\": \"validation\",\n",
            "            \"num_samples\": 423\n",
            "        }\n",
            "    },\n",
            "    \"classes\": [\n",
            "        \"Car\",\n",
            "        \"Van\",\n",
            "        \"Truck\",\n",
            "        \"Pedestrian\",\n",
            "        \"Person_sitting\",\n",
            "        \"Cyclist\",\n",
            "        \"Tram\",\n",
            "        \"Misc\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "fiftyone zoo datasets info kitti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKITSvs6HqUj"
      },
      "source": [
        "The snippet below uses `fiftyone convert` to convert the test split of the CIFAR-10 dataset to [fiftyone.types.COCODetectionDataset](https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html#cocodetectiondataset) format, which writes the dataset to disk with annotations in [COCO format](https://cocodataset.org/#format-data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UrN_d3pHqUj",
        "outputId": "8cff3d9f-7579-4bba-a15f-82a5accd6c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from '~/fiftyone/kitti/validation'\n",
            "Input format 'fiftyone.types.dataset_types.FiftyOneImageDetectionDataset'\n",
            " 100% |███████| 423/423 [1.2s elapsed, 0s remaining, 351.0 samples/s]         \n",
            "Import complete\n",
            "Exporting dataset to '/tmp/fiftyone/kitti-coco'\n",
            "Export format 'fiftyone.types.dataset_types.COCODetectionDataset'\n",
            " 100% |███████| 423/423 [4.4s elapsed, 0s remaining, 96.1 samples/s]       \n",
            "Export complete\n"
          ]
        }
      ],
      "source": [
        "INPUT_DIR=$(fiftyone zoo datasets find kitti --split validation)\n",
        "OUTPUT_DIR=/tmp/fiftyone/kitti-coco\n",
        "\n",
        "fiftyone convert \\\n",
        "    --input-dir ${INPUT_DIR} --input-type fiftyone.types.FiftyOneImageDetectionDataset \\\n",
        "    --output-dir ${OUTPUT_DIR} --output-type fiftyone.types.COCODetectionDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL4vFnc8HqUk"
      },
      "source": [
        "Let's verify that the conversion happened as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKLSWRu3HqUk",
        "outputId": "9d8af606-6ed5-45c6-ab8e-66369375a357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 880\n",
            "drwxr-xr-x    4 voxel51  wheel   128B Jul 14 11:24 .\n",
            "drwxr-xr-x    5 voxel51  wheel   160B Jul 14 11:24 ..\n",
            "drwxr-xr-x  425 voxel51  wheel    13K Jul 14 11:24 data\n",
            "-rw-r--r--    1 voxel51  wheel   437K Jul 14 11:24 labels.json\n"
          ]
        }
      ],
      "source": [
        "ls -lah /tmp/fiftyone/kitti-coco/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR520QehHqUk",
        "outputId": "974a0e50-815e-43af-8e41-49c4c5dca16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 171008\n",
            "drwxr-xr-x  425 voxel51  wheel    13K Jul 14 11:24 .\n",
            "drwxr-xr-x    4 voxel51  wheel   128B Jul 14 11:24 ..\n",
            "-rw-r--r--    1 voxel51  wheel   195K Jul 14 11:24 000001.jpg\n",
            "-rw-r--r--    1 voxel51  wheel   191K Jul 14 11:24 000002.jpg\n",
            "-rw-r--r--    1 voxel51  wheel   167K Jul 14 11:24 000003.jpg\n",
            "-rw-r--r--    1 voxel51  wheel   196K Jul 14 11:24 000004.jpg\n",
            "-rw-r--r--    1 voxel51  wheel   224K Jul 14 11:24 000005.jpg\n",
            "-rw-r--r--    1 voxel51  wheel   195K Jul 14 11:24 000006.jpg\n",
            "-rw-r--r--    1 voxel51  wheel   177K Jul 14 11:24 000007.jpg\n"
          ]
        }
      ],
      "source": [
        "ls -lah /tmp/fiftyone/kitti-coco/data | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAwhKg3LHqUk",
        "outputId": "a383244e-2149-4abb-a136-2cb5413edac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"info\": {\n",
            "        \"year\": \"\",\n",
            "        \"version\": \"\",\n",
            "        \"description\": \"Exported from FiftyOne\",\n",
            "        \"contributor\": \"\",\n",
            "        \"url\": \"https://voxel51.com/fiftyone\",\n",
            "        \"date_created\": \"2020-07-14T11:24:40\"\n",
            "    },\n",
            "    \"licenses\": [],\n",
            "    \"categories\": [\n",
            "        {\n",
            "            \"id\": 0,\n",
            "            \"name\": \"Car\",\n",
            "            \"supercategory\": \"none\"\n",
            "        },\n",
            "        {\n",
            "            \"id\": 1,\n",
            "            \"name\": \"Cyclist\",\n",
            "            \"supercategory\": \"none\"\n",
            "...\n",
            "            \"area\": 4545.8,\n",
            "            \"segmentation\": null,\n",
            "            \"iscrowd\": 0\n",
            "        },\n",
            "        {\n",
            "            \"id\": 3196,\n",
            "            \"image_id\": 422,\n",
            "            \"category_id\": 3,\n",
            "            \"bbox\": [\n",
            "                367.2,\n",
            "                107.3,\n",
            "                36.2,\n",
            "                105.2\n",
            "            ],\n",
            "            \"area\": 3808.2,\n",
            "            \"segmentation\": null,\n",
            "            \"iscrowd\": 0\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "cat /tmp/fiftyone/kitti-coco/labels.json | python -m json.tool 2> /dev/null | head -20\n",
        "echo \"...\"\n",
        "cat /tmp/fiftyone/kitti-coco/labels.json | python -m json.tool 2> /dev/null | tail -20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsYA12gmHqUn"
      },
      "source": [
        "Now let's convert from COCO format to [CVAT Image format](https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html#cvatimageformat) format!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h2oezp7HqUn",
        "outputId": "e354318a-4ac5-4919-8ab4-302724dfe3c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from '/tmp/fiftyone/kitti-coco'\n",
            "Input format 'fiftyone.types.dataset_types.COCODetectionDataset'\n",
            " 100% |███████| 423/423 [2.0s elapsed, 0s remaining, 206.4 samples/s]      \n",
            "Import complete\n",
            "Exporting dataset to '/tmp/fiftyone/kitti-cvat'\n",
            "Export format 'fiftyone.types.dataset_types.CVATImageDataset'\n",
            " 100% |███████| 423/423 [1.3s elapsed, 0s remaining, 323.7 samples/s]         \n",
            "Export complete\n"
          ]
        }
      ],
      "source": [
        "INPUT_DIR=/tmp/fiftyone/kitti-coco\n",
        "OUTPUT_DIR=/tmp/fiftyone/kitti-cvat\n",
        "\n",
        "fiftyone convert \\\n",
        "    --input-dir ${INPUT_DIR} --input-type fiftyone.types.COCODetectionDataset \\\n",
        "    --output-dir ${OUTPUT_DIR} --output-type fiftyone.types.CVATImageDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z6FwUM3HqUn"
      },
      "source": [
        "Let's verify that the conversion happened as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQtqDBPsHqUo",
        "outputId": "336dd8b7-34e7-44ec-ecce-6daa56b9b2d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 584\n",
            "drwxr-xr-x    4 voxel51  wheel   128B Jul 14 11:25 .\n",
            "drwxr-xr-x    6 voxel51  wheel   192B Jul 14 11:25 ..\n",
            "drwxr-xr-x  425 voxel51  wheel    13K Jul 14 11:25 data\n",
            "-rw-r--r--    1 voxel51  wheel   289K Jul 14 11:25 labels.xml\n"
          ]
        }
      ],
      "source": [
        "ls -lah /tmp/fiftyone/kitti-cvat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEV2r4J5HqUo",
        "outputId": "472a1551-9edb-4d38-be81-07dbbff05495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<annotations>\n",
            "    <version>1.1</version>\n",
            "    <meta>\n",
            "        <task>\n",
            "            <size>423</size>\n",
            "            <mode>annotation</mode>\n",
            "            <labels>\n",
            "                <label>\n",
            "                    <name>Car</name>\n",
            "                    <attributes>\n",
            "                    </attributes>\n",
            "                </label>\n",
            "                <label>\n",
            "                    <name>Cyclist</name>\n",
            "                    <attributes>\n",
            "                    </attributes>\n",
            "                </label>\n",
            "                <label>\n",
            "                    <name>Misc</name>\n",
            "...\n",
            "        <box label=\"Pedestrian\" xtl=\"360\" ytl=\"116\" xbr=\"402\" ybr=\"212\">\n",
            "        </box>\n",
            "        <box label=\"Pedestrian\" xtl=\"396\" ytl=\"120\" xbr=\"430\" ybr=\"212\">\n",
            "        </box>\n",
            "        <box label=\"Pedestrian\" xtl=\"413\" ytl=\"112\" xbr=\"483\" ybr=\"212\">\n",
            "        </box>\n",
            "        <box label=\"Pedestrian\" xtl=\"585\" ytl=\"80\" xbr=\"646\" ybr=\"215\">\n",
            "        </box>\n",
            "        <box label=\"Pedestrian\" xtl=\"635\" ytl=\"94\" xbr=\"688\" ybr=\"212\">\n",
            "        </box>\n",
            "        <box label=\"Pedestrian\" xtl=\"422\" ytl=\"85\" xbr=\"469\" ybr=\"210\">\n",
            "        </box>\n",
            "        <box label=\"Pedestrian\" xtl=\"457\" ytl=\"93\" xbr=\"520\" ybr=\"213\">\n",
            "        </box>\n",
            "        <box label=\"Pedestrian\" xtl=\"505\" ytl=\"101\" xbr=\"548\" ybr=\"206\">\n",
            "        </box>\n",
            "        <box label=\"Pedestrian\" xtl=\"367\" ytl=\"107\" xbr=\"403\" ybr=\"212\">\n",
            "        </box>\n",
            "    </image>\n",
            "</annotations>"
          ]
        }
      ],
      "source": [
        "cat /tmp/fiftyone/kitti-cvat/labels.xml | head -20\n",
        "echo \"...\"\n",
        "cat /tmp/fiftyone/kitti-cvat/labels.xml | tail -20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9OOLPJmHqUo"
      },
      "source": [
        "## Cleanup\n",
        "\n",
        "You can cleanup the files generated by this recipe by running the command below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mXa3Nt-HqUo"
      },
      "outputs": [],
      "source": [
        "rm -rf /tmp/fiftyone"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Bash",
      "language": "bash",
      "name": "bash"
    },
    "language_info": {
      "codemirror_mode": "shell",
      "file_extension": ".sh",
      "mimetype": "text/x-sh",
      "name": "bash"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}